<h1>Feature: Scenarios could be tagged</h1>
<h2>Background:</h2>
<ul>
<li>Given File &quot;steps.feature&quot; with content:
<pre><code class="language-gherkin">Feature: Steps are executed by corresponding step keyword decorator
  @passed
  Scenario: Passed
    Given I produce passed test

  @failed
  Scenario: Failed
    Given I produce failed test

  @both
  Rule:
    Scenario: Passed
      Given I produce passed test

    Scenario: Failed
      Given I produce failed test
</code></pre>
</li>
<li>Given File &quot;pytest.ini&quot; with content:
<pre><code class="language-ini">[pytest]
markers =
  passed
  failed
  both
</code></pre>
</li>
<li>And File &quot;conftest.py&quot; with content:
<pre><code class="language-python">from pytest_bdd.compatibility.pytest import fail
from pytest_bdd import given

@given('I produce passed test')
def passing_step():
  ...

@given('I produce failed test')
def failing_step():
  fail('Enforce fail')
</code></pre>
</li>
</ul>
<h2>Scenario:</h2>
<ul>
<li>
<p>When run pytest</p>
<table>
<thead>
<tr>
<th>cli_args</th>
<th>-m</th>
<th>passed</th>
</tr>
</thead>
</table>
</li>
<li>
<p>Then pytest outcome must contain tests with statuses:</p>
<table>
<thead>
<tr>
<th>passed</th>
<th>failed</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>
</li>
</ul>
<h2>Scenario:</h2>
<ul>
<li>
<p>When run pytest</p>
<table>
<thead>
<tr>
<th>cli_args</th>
<th>-m</th>
<th>failed</th>
</tr>
</thead>
</table>
</li>
<li>
<p>Then pytest outcome must contain tests with statuses:</p>
<table>
<thead>
<tr>
<th>passed</th>
<th>failed</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>1</td>
</tr>
</tbody>
</table>
</li>
</ul>
<h2>Scenario:</h2>
<ul>
<li>
<p>When run pytest</p>
<table>
<thead>
<tr>
<th>cli_args</th>
<th>-m</th>
<th>passed or failed</th>
</tr>
</thead>
</table>
</li>
<li>
<p>Then pytest outcome must contain tests with statuses:</p>
<table>
<thead>
<tr>
<th>passed</th>
<th>failed</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>
</li>
</ul>
<h2>Scenario:</h2>
<ul>
<li>
<p>When run pytest</p>
<table>
<thead>
<tr>
<th>cli_args</th>
<th>-m</th>
<th>not both</th>
</tr>
</thead>
</table>
</li>
<li>
<p>Then pytest outcome must contain tests with statuses:</p>
<table>
<thead>
<tr>
<th>passed</th>
<th>failed</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>
</li>
</ul>
<h2>Scenario:</h2>
<ul>
<li>
<p>When run pytest</p>
<table>
<thead>
<tr>
<th>cli_args</th>
<th>-m</th>
<th>both</th>
</tr>
</thead>
</table>
</li>
<li>
<p>Then pytest outcome must contain tests with statuses:</p>
<table>
<thead>
<tr>
<th>passed</th>
<th>failed</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>
</li>
</ul>
<h2>Scenario:</h2>
<ul>
<li>When run pytest</li>
<li>Then pytest outcome must contain tests with statuses:
<table>
<thead>
<tr>
<th>passed</th>
<th>failed</th>
</tr>
</thead>
<tbody>
<tr>
<td>2</td>
<td>2</td>
</tr>
</tbody>
</table>
</li>
</ul>
